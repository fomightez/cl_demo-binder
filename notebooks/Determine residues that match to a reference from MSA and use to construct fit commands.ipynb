{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine residues that match to a reference from MSA and use to construct fit commands\n",
    "\n",
    "Often one wants to superimpose (a.k.a., overlay/superpse/fit/dock) similar macromolecular structures with one another.  You always need to know matching 'spine' or 'backbone' atoms to get Pymol or Jmols fit/compare commands to work. With several structures, some of which can be just fragments, it can be tedious, and sometimes error-pronem to do the determination of matching atoms by hand. This notebook shows how to determine what is there and builds up in steps to generating the fit commands for the same chains shared by different structures.\n",
    "\n",
    "Because often times you be superimposing a theoretical model on a known structure, or want to use a specific structure as the example structure, you'll often have a sequence in your multiple sequence alignment that corresponds to a 'reference structure'. The 'reference id' used here refers to the identifier of that sequence.\n",
    "\n",
    "The fit commands are intended to be used in Pymol and Jmol, with separate sections for each one.\n",
    "\n",
    "The process relies initially on use of a script entitled `MSA_to_corresponding_residue_numbers.py`. Because that lays the groundwork for the process of creating commands from an alignment that can be used on the molecular structure visualization, and I didn't have a demo of that script yet elsewhere, I illustrate use of that script first. \n",
    "\n",
    "Technically, that script is a 'sequence analysis' script; however, it, like `categorize_residues_based_on_conservation_relative_consensus_line.py` demonstrated in another notebook here, is very useful for bridging sequence analysis to molecular structure analysis as I hope the later part of this notebook illustrates.\n",
    "\n",
    "\n",
    "----\n",
    " \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>If you haven't used one of these notebooks before, they're basically web pages in which you can write, edit, and run live code. They're meant to encourage experimentation, so don't feel nervous. Just try running a few cells and see what happens!.</p>\n",
    "\n",
    "<p>\n",
    "    Some tips:\n",
    "    <ul>\n",
    "        <li>Code cells have boxes around them. When you hover over them a <i class=\"fa-step-forward fa\"></i> icon appears.</li>\n",
    "        <li>To run a code cell either click the <i class=\"fa-step-forward fa\"></i> icon, or click on the cell and then hit <b>Shift+Enter</b>. The <b>Shift+Enter</b> combo will also move you to the next cell, so it's a quick way to work through the notebook.</li>\n",
    "        <li>While a cell is running a <b>*</b> appears in the square brackets next to the cell. Once the cell has finished running the asterisk will be replaced with a number.</li>\n",
    "        <li>In most cases you'll want to start from the top of notebook and work your way down running each cell in turn. Later cells might depend on the results of earlier ones.</li>\n",
    "        <li>To edit a code cell, just click on it and type stuff. Remember to run the cell once you've finished editing.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Preparation\n",
    "\n",
    "The next cell will retrieve the necessary scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 29699  100 29699    0     0   149k      0 --:--:-- --:--:-- --:--:--  149k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12393  100 12393    0     0  81532      0 --:--:-- --:--:-- --:--:-- 82072\n"
     ]
    }
   ],
   "source": [
    "#get scripts to use here\n",
    "!curl -OL https://raw.githubusercontent.com/fomightez/sequencework/master/alignment-utilities/MSA_to_corresponding_residue_numbers.py\n",
    "!curl -OL https://raw.githubusercontent.com/fomightez/sequencework/master/alignment-utilities/check_seq_frag_in_MSAclustal_intact_viaFASTA.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alignment file is needed as input. The next cell will handle retrieving one.\n",
    "\n",
    "Details of the retrieved alignment:\n",
    "\n",
    "Fasta-formattted sequences were downloaded from under 'Sequence' at [here for Stv1p](https://www.yeastgenome.org/locus/S000004658/protein) and [here for Vph1p](https://www.yeastgenome.org/locus/S000005796/protein). These were then combined into one file, the asterisks at the end of each sequence removed (in order to avoid the error `*** WARNING ***  Invalid character '*' in FASTA sequence data, ignored`), combined with two human sequences, and submitted for alignment by [MUSCLE here](https://www.ebi.ac.uk/Tools/msa/muscle/). Default settings were used. The alignment was produced in Clustal format with consensus symbols line along the bottom.\n",
    "\n",
    "Furthermore, for purposes of illustration here, **the residues that didn't pair with the start of all where left off. MEANING THAT SEVERAL OF THESE SEQUENCES DON'T REPRESENT THE FULL PROTEIN SEQUENCE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  6139  100  6139    0     0  28160      0 --:--:-- --:--:-- --:--:-- 28160\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3633  100  3633    0     0  20071      0 --:--:-- --:--:-- --:--:-- 19961\n"
     ]
    }
   ],
   "source": [
    "# Get an alignment file (actually two because going to show with all residues first)\n",
    "!curl -o alignment.clw https://gist.githubusercontent.com/fomightez/f46b0624f1d8e3abb6ff908fc447e63b/raw/6abce38569475c68fa32182c4e0eaadbb8b0cf3b/uw_yeast_plus_two_human_homologs.clw\n",
    "!curl -o alignment_with_all_residues.clw https://gist.githubusercontent.com/fomightez/f46b0624f1d8e3abb6ff908fc447e63b/raw/6abce38569475c68fa32182c4e0eaadbb8b0cf3b/Stv1p_Vph1p_muscle_alignment.clw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTAL multiple sequence alignment by MUSCLE (3.8)\n",
      "\n",
      "\n",
      "BAH13127.1      FRSEEMTLA--QLFLQSEAAYCCVSELGELGKVQFRDLNPDVNVFQRKFVNEVRRCEEMD\n",
      "EAW98433.1      MTATEMRCVGRSFYIHG---------------LSIIKLNQNVSSFQRKFVGEVKRCEELE\n",
      "VPH1            FRSAEMALV--QFYIPQEISRDSAYTLGQLGLVQFRDLNSKVRAFQRTFVNEIRRLDNVE\n",
      "STV1            FRSADMTYV--QLYIPLEVIREVTFLLGKMSVFMVMDLNKDLTAFQRGYVNQLRRFDEVE\n",
      "                : : :*  .  .:::                 . . .** .:  *** :*.::.* ::::\n",
      "\n",
      "BAH13127.1      RKLRFVEKEIRKANIPIM------------DTGENPEVPFPRDMI---------------\n"
     ]
    }
   ],
   "source": [
    "#verify have alignment file\n",
    "!head alignment.clw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the sequence of all but one don't begin with methionine. for purposes of illustration here, **the residues that didn't pair with the start of all where left off. MEANING THAT SEVERAL OF THESE SEQUENCES DON'T REPRESENT THE FULL PROTEIN SEQUENCE.**\n",
    "\n",
    "You'll want to upload your own alignments to the active Jupyter session in the typical way; if you can click the Jupyter logo in the upper right you'll be taken to a dashboard with a file handing user interface. (Or once it is retrieved, open and replace the contents of `alignment.clw` with your own alignment.)\n",
    "\n",
    "Note, because white space is critical for the consensus symbols line, it is  best to save the alignment file directly from EMBL-EBI and use that file as input for this script, rather than doing copy-paste from the site. For example, via copy-paste it may be easy to miss the spaces on the last line of the consensus symbols line in the case of two sequences that mismatch for the span of the entire last row of an alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check sequence of edited alignment\n",
    "\n",
    "In the process of editing a multiple sequence file or collecting portions to use to align, it is easy to erroneously delete sequence. This section will demonstrate using `check_seq_frag_in_MSAclustal_intact_viaFASTA.py` to make sure nothing in the fragment used here as been deleted, and verify the edited sequene in the alignment file is valid. It checks against a user-provided FASTA. It is suggested this comes directly from an 'official' source. It is related to **a similar, yet different script** `check_seq_in_MSAclustal_consistent_with_FASTA.py` **that makes sure nothing AT ALL is different/deleted relative the FASTA sequence**. `check_seq_frag_in_MSAclustal_intact_viaFASTA.py` to be used here is not concerned with either the start or end of the sequence. \n",
    "\n",
    "The reason that `check_seq_frag_in_MSAclustal_intact_viaFASTA.py` is used here is because part of the sequences in the MSA to be used here have been deleted and in order for the `MSA_to_corresponding_residue_numbers.py` script to yield useable data it is important that the fragment it is aligned to is intact or the numbers won't match the reference structure.\n",
    "\n",
    "For the FASTA file, VPH1 and STV1 came from the [Saccharomyces Genome Database (SGD)](https://www.yeastgenome.org/) page for each respective encoding gene. From the pages for a particular gene, you can surf to the 'Protein' tab (example: [STV1 protein tab](https://www.yeastgenome.org/locus/S000004658/protein)) and then under 'Sequence' about half way down the page , click on the button 'Download Sequence (.fsa)' to get a FASTA file for the protein corresponding to that gene.\n",
    "\n",
    "Now to use that FASTA check if the fragment present in MSA is in intact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File \"check_seq_frag_in_MSAclustal_intact_viaFASTA.py\", line 256\n",
      "    if seq infasta_seq:\n",
      "                     ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!python check_seq_frag_in_MSAclustal_intact_viaFASTA.py alignment.clw VPH1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! Sequence of one of the sequences in the manually-edited multiple sequence alignment has been confirmed against the official recordv verifying no deletions were introduced into the fragment during editing. It is best the process is repeated with any others as well.\n",
    "\n",
    "Now that we know that the fragment is intact (and could determine for others) we can continue on to next section where the multiple sequence alignment is used to collect residues that correspond to the reference structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use residue script via command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script takes...\n",
    "\n",
    "#### Display `USAGE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: MSA_to_corresponding_residue_numbers.py [-h]\n",
      "                                               ALIGNMENT_FILE REF_ID\n",
      "                                               [N [N ...]]\n",
      "\n",
      "MSA_to_corresponding_residue_numbers.py takes akes a multiple sequence\n",
      "alignment in Clustal format and determines the corresponding residue numbers\n",
      "for aligned residues for a specified reference sequence in the alignment and\n",
      "the pairing of it with every other aligned sequence in the multiple sequence\n",
      "alignment. The reference sequence is specified by the identifier at the start\n",
      "of each line in the sequence blocks. **** Script by Wayne Decatur (fomightez @\n",
      "github) ***\n",
      "\n",
      "positional arguments:\n",
      "  ALIGNMENT_FILE  Name of file of alignment text file (CLUSTAL format).\n",
      "  REF_ID          Identifier that matches the sequence in the MSA to use as a\n",
      "                  reference to get matches to other sequences. Presumably,\n",
      "                  this sequence has a corresponding structural model\n",
      "                  available.\n",
      "  N               OPTIONAL IN MANY CASES: Provide an integer specifying the\n",
      "                  start position for each sequence in the provided alignment,\n",
      "                  if at least one of them isn't beginning at the first residue\n",
      "                  in the sequence. Seperate each integer with a space. IF ALL\n",
      "                  BEGIN AT ONE, NO REASON TO INCLUDE SUCH A LIST.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help      show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "!python MSA_to_corresponding_residue_numbers.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command line use example #1: basic command (tabular text files output)\n",
    "\n",
    "The minimum the script needs to analyze an alignment is to specify the alignment file name followed by the designation of the sequence to use as the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "**NOTE: gap indicator in this script is currently set to '-'. If\n",
      "that does not match what provided alignment uses to indicate gaps,\n",
      "please change the setting within the script code under\n",
      "'USER ADJUSTABLE VALUES' around line 130 (give or take a few).**\n",
      "Alignment file read...VPH1 reference sequence collected from alignment...query compared...\n",
      "made match pairings into intervals of start and end where possible...\n",
      "\n",
      "made dataframe of matched start and ends...DONE.\n",
      "\n",
      "File 'VPH1_residues_matched_to_STV1.tsv' saved.\n"
     ]
    }
   ],
   "source": [
    "%run MSA_to_corresponding_residue_numbers.py alignment_with_all_residues.clw VPH1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPH1_start\tVPH1_end\tSTV1_start\tSTV1_end\n",
      "2\t84\t1\t83\n",
      "90\t92\t84\t86\n",
      "93\t107\t91\t105\n",
      "108\t152\t117\t161\n",
      "153\t171\t167\t185\n",
      "172\t186\t189\t203\n",
      "187\t222\t240\t275\n",
      "225\t267\t276\t318\n",
      "271\t325\t319\t373\n"
     ]
    }
   ],
   "source": [
    "!head VPH1_residues_matched_to_STV1.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command line use example #2: designate the starting residue shown in the alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it many cases one or some of the sequences won't have the initial or perhaps the end sequences. If the missing residues are at the beginning, an offset value needs to be provided **If at least one sequence in the multiple sequence alignment doesn't begin with residue number 1 and you want to provide an offset value, a value for each sequence must be provided. Simply put `1` if it startes with the first residue.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "**NOTE: gap indicator in this script is currently set to '-'. If\n",
      "that does not match what provided alignment uses to indicate gaps,\n",
      "please change the setting within the script code under\n",
      "'USER ADJUSTABLE VALUES' around line 130 (give or take a few).**\n",
      "Alignment file read...VPH1 reference sequence collected from alignment...query compared...query compared...query compared...\n",
      "made match pairings into intervals of start and end where possible...\n",
      "\n",
      "made dataframes of matched start and ends...DONE.\n",
      "\n",
      "File 'VPH1_residues_matched_to_BAH13127.1.tsv' saved.\n",
      "File 'VPH1_residues_matched_to_EAW98433.1.tsv' saved.\n",
      "File 'VPH1_residues_matched_to_STV1.tsv' saved.\n"
     ]
    }
   ],
   "source": [
    "%run MSA_to_corresponding_residue_numbers.py alignment.clw VPH1 5 1 5 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note if you are working in Python subsequently, you should check out the next section where importing the main function of the script into a Jupyter notebook or IPython session and passing dataframes back into a Jupyter notebook directly are illustrated. This option offers the most easy with using the data in downstream steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use residue matching function via import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to being able to be run from the command line, the main function imported into a Jupyter notebook (or IPython session) and it can pass back dataframe(s) with the results. This section illustrates that.\n",
    "\n",
    "First you import the function into the notebook or IPython environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MSA_to_corresponding_residue_numbers import MSA_to_corresponding_residue_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That command looks a bit redundant because the first 'from' is addressing the name of the script. The convention / syntax is not to include the extension though. The second part is specifying to import the function `MSA_to_corresponding_residue_numbers()`.\n",
    "\n",
    "Now that `MSA_to_corresponding_residue_numbers()` is imported, it can be used. As with using the script fom the command line, the function has a number of options, including a way to provide a list of residues in the case one or more sequences in the multiple sequence alignment don't begin with residue number one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function use example #1: basic command\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "**NOTE: gap indicator in this script is currently set to '-'. If\n",
      "that does not match what provided alignment uses to indicate gaps,\n",
      "please change the setting within the script code under\n",
      "'USER ADJUSTABLE VALUES' around line 130 (give or take a few).**\n",
      "Alignment file read...VPH1 reference sequence collected from alignment...query compared...\n",
      "made match pairings into intervals of start and end where possible...\n",
      "\n",
      "made dataframe of matched start and ends...DONE.\n",
      "\n",
      "File 'VPH1_residues_matched_to_STV1.tsv' saved.\n"
     ]
    }
   ],
   "source": [
    "MSA_to_corresponding_residue_numbers(\"alignment_with_all_residues.clw\",\"VPH1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPH1_start\tVPH1_end\tSTV1_start\tSTV1_end\n",
      "2\t84\t1\t83\n",
      "90\t92\t84\t86\n",
      "93\t107\t91\t105\n",
      "108\t152\t117\t161\n",
      "153\t171\t167\t185\n",
      "172\t186\t189\t203\n",
      "187\t222\t240\t275\n",
      "225\t267\t276\t318\n",
      "271\t325\t319\t373\n"
     ]
    }
   ],
   "source": [
    "!head VPH1_residues_matched_to_STV1.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function use example #2: supply start residues\n",
    "\n",
    "As with the command line version, if any sequence doesn't begin with residue number one a list of the first residue positions for all sequences must be supplied. When calling with the function use `supplied_start_pos` argument to supply a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "**NOTE: gap indicator in this script is currently set to '-'. If\n",
      "that does not match what provided alignment uses to indicate gaps,\n",
      "please change the setting within the script code under\n",
      "'USER ADJUSTABLE VALUES' around line 130 (give or take a few).**\n",
      "Alignment file read...VPH1 reference sequence collected from alignment...query compared...query compared...query compared...\n",
      "made match pairings into intervals of start and end where possible...\n",
      "\n",
      "made dataframes of matched start and ends...DONE.\n",
      "\n",
      "File 'VPH1_residues_matched_to_BAH13127.1.tsv' saved.\n",
      "File 'VPH1_residues_matched_to_EAW98433.1.tsv' saved.\n",
      "File 'VPH1_residues_matched_to_STV1.tsv' saved.\n"
     ]
    }
   ],
   "source": [
    "MSA_to_corresponding_residue_numbers(\"alignment.clw\",\"VPH1\", supplied_start_pos = [5,1,5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPH1_start\tVPH1_end\tSTV1_start\tSTV1_end\n",
      "5\t80\t5\t80\n",
      "86\t88\t81\t83\n",
      "89\t103\t88\t102\n",
      "104\t148\t114\t158\n",
      "149\t167\t164\t182\n",
      "168\t182\t186\t200\n",
      "183\t218\t237\t272\n",
      "221\t263\t273\t315\n",
      "267\t321\t316\t370\n"
     ]
    }
   ],
   "source": [
    "!head VPH1_residues_matched_to_STV1.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function use example #3: return dataframes\n",
    "\n",
    "For those wishing to utilize this data in Python, a dictionary of dataframes can be returned by setting `return_dfs` to true. The identifier of the query sequence in the match will by the key. The reference idenitifier is returned as well so that it will be a variable ready for subsequent use.\n",
    "\n",
    "The next cell demonstrates getting the dataframes in as active objects in the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAH13127.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "**NOTE: gap indicator in this script is currently set to '-'. If\n",
      "that does not match what provided alignment uses to indicate gaps,\n",
      "please change the setting within the script code under\n",
      "'USER ADJUSTABLE VALUES' around line 130 (give or take a few).**\n",
      "Alignment file read...VPH1 reference sequence collected from alignment...query compared...query compared...query compared...\n",
      "made match pairings into intervals of start and end where possible...\n",
      "\n",
      "made dataframes of matched start and ends...DONE.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VPH1_start</th>\n",
       "      <th>VPH1_end</th>\n",
       "      <th>BAH13127.1_start</th>\n",
       "      <th>BAH13127.1_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>103</td>\n",
       "      <td>81</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>136</td>\n",
       "      <td>96</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>166</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169</td>\n",
       "      <td>448</td>\n",
       "      <td>114</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VPH1_start  VPH1_end  BAH13127.1_start  BAH13127.1_end\n",
       "0           5        80                 5              80\n",
       "1          89       103                81              95\n",
       "2         126       136                96             106\n",
       "3         160       166               107             113\n",
       "4         169       448               114             393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAW98433.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VPH1_start</th>\n",
       "      <th>VPH1_end</th>\n",
       "      <th>EAW98433.1_start</th>\n",
       "      <th>EAW98433.1_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>148</td>\n",
       "      <td>79</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VPH1_start  VPH1_end  EAW98433.1_start  EAW98433.1_end\n",
       "0           5        13                 1               9\n",
       "1          14        19                12              17\n",
       "2          35        80                18              63\n",
       "3          89       103                64              78\n",
       "4         105       148                79             122"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STV1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VPH1_start</th>\n",
       "      <th>VPH1_end</th>\n",
       "      <th>STV1_start</th>\n",
       "      <th>STV1_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>103</td>\n",
       "      <td>88</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>148</td>\n",
       "      <td>114</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>167</td>\n",
       "      <td>164</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VPH1_start  VPH1_end  STV1_start  STV1_end\n",
       "0           5        80           5        80\n",
       "1          86        88          81        83\n",
       "2          89       103          88       102\n",
       "3         104       148         114       158\n",
       "4         149       167         164       182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "ref_id, dfs_by_id = MSA_to_corresponding_residue_numbers(\"alignment.clw\",\"VPH1\", return_dfs = True , supplied_start_pos = [5,1,5,5])\n",
    "for id_,df in dfs_by_id.items():\n",
    "    print(id_)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final section of the notebook, below, builds on the outout of dataframes to produce molecular visualization commands for use in fitting the matching residues in structures using Pymol and/or Jmol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the matched residues to make Pymol fit commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section builds on the dataframes output to produce molecular visualization commands for use in Pymol. Information on structure being used:\n",
    "[6C6L: Yeast Vacuolar ATPase Vo in lipid nanodisc](http://www.rcsb.org/structure/6C6L). VPH1 is Chain A\n",
    "\n",
    "First we'll run the command to make sure the related dataframe is in the namespace of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "**NOTE: gap indicator in this script is currently set to '-'. If\n",
      "that does not match what provided alignment uses to indicate gaps,\n",
      "please change the setting within the script code under\n",
      "'USER ADJUSTABLE VALUES' around line 130 (give or take a few).**\n",
      "Alignment file read...VPH1 reference sequence collected from alignment...query compared...query compared...query compared...\n",
      "made match pairings into intervals of start and end where possible...\n",
      "\n",
      "made dataframes of matched start and ends...DONE.\n"
     ]
    }
   ],
   "source": [
    "from MSA_to_corresponding_residue_numbers import MSA_to_corresponding_residue_numbers\n",
    "ref_id, dfs_by_id = MSA_to_corresponding_residue_numbers(\"alignment.clw\",\"VPH1\", return_dfs = True , supplied_start_pos = [5,1,5,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataframes can be used to make commands based on the identifiers and matching residue numbering.\n",
    "\n",
    "Some additional data needs to be provided because the equivalent chains weren't yet provided. For example, the model made of STV1 has chain designation of 'A'. Even though  the structure [PDB id: 6C6L](http://www.rcsb.org/structure/6C6L) is quite complex with fifteen chains (eight unique), VPH1 is designated chain 'A' for reasons related to the subunit nomenclature. \n",
    "\n",
    "It won't always be this simple. One model might have a protein if interest chain 'I', while a homolog is chain 'K' in another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ranges_o_residues_resolved_per_chain_pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4e0e5da16aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# generate commands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mformatted_commands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchain_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mranges_o_residues_resolved_per_chain_pairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mformatted_commands\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"select {structures[indx].id}ch{chain}CA,\"\u001b[0m \u001b[0;31m#`CA` at end stands for `name CA` / alpha-carbon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ranges_o_residues_resolved_per_chain_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "# further prep for generating commands\n",
    "ref_id_chain = 'A' # for VPH1, from http://www.rcsb.org/structure/6C6L\n",
    "query_chains_by_id = {'BAH13127.1':'G',\n",
    "                      'EAW98433.1 ':'H',\n",
    "                      'STV1':'A'}\n",
    "\n",
    "# generate commands\n",
    "formatted_commands = \"\"\n",
    "for chain_pair in ranges_o_residues_resolved_per_chain_pairs:\n",
    "    for indx,chain in enumerate(chain_pair):\n",
    "        formatted_commands += f\"select {structures[indx].id}ch{chain}CA,\" #`CA` at end stands for `name CA` / alpha-carbon\n",
    "        formatted_commands += \"|\".join( f\" {structures[indx].id} and resid {pos_range} and chain {chain} and name CA \" \n",
    "                                       for pos_range in ranges_o_residues_resolved_per_chain_pairs[chain_pair] ) \n",
    "        #for pos_range in ranges_o_residues_resolved_per_chain_pairs[chain_pair]:\n",
    "         #   formatted_commands += f\"{structures[indx].id} and resid {pos_range} and chain {chain} and name CA\"\n",
    "        formatted_commands += \"\\n\"\n",
    "\n",
    "# residues_resolved_per_chain_b\n",
    "shared_positions_per_chain_pairs\n",
    "ranges_o_residues_resolved_per_chain_pairs\n",
    "print(\"\\n\\n\")\n",
    "print (\"FORMATTED PYMOL COMMANDS:\")\n",
    "print(\" \")\n",
    "print(formatted_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing commands for fitting matching residues of chains shared between two structures\n",
    "\n",
    "The output can be used in Pymol to structurally align the chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions of resolved residues shared between two structures formatted into pair_fit commands\n",
    "allow_MSE = True\n",
    "\n",
    "from Bio.PDB import *\n",
    "from collections import defaultdict\n",
    "\n",
    "def range_extract(lst):\n",
    "    # from https://www.rosettacode.org/wiki/Range_extraction#Python\n",
    "    'Yield 2-tuple ranges or 1-tuple single elements from list of increasing ints'\n",
    "    lenlst = len(lst)\n",
    "    i = 0\n",
    "    while i< lenlst:\n",
    "        low = lst[i]\n",
    "        while i <lenlst-1 and lst[i]+1 == lst[i+1]: i +=1\n",
    "        hi = lst[i]\n",
    "        if   hi - low >= 2:\n",
    "            yield (low, hi)\n",
    "        elif hi - low == 1:\n",
    "            yield (low,)\n",
    "            yield (hi,)\n",
    "        else:\n",
    "            yield (low,)\n",
    "        i += 1\n",
    "def printr(ranges):\n",
    "    # from https://www.rosettacode.org/wiki/Range_extraction#Python\n",
    "    print( ','.join( (('%i-%i' % r) if len(r) == 2 else '%i' % r)\n",
    "                     for r in ranges ) )\n",
    "\n",
    "    \n",
    "def get_nice_ranges(ranges):\n",
    "    return [ (('%i-%i' % r) if len(r) == 2 else '%i' % r) for r in ranges ]\n",
    "\n",
    "def get_nice_ranges_wcolon(ranges):\n",
    "    return [ (('%i:%i' % r) if len(r) == 2 else '%i' % r) for r in ranges ]\n",
    "\n",
    "# Read in structure a ('first' structure)\n",
    "structure = PDBParser().get_structure('3IAB', '3IAB.pdb')\n",
    "residues_resolved_per_chain = defaultdict(list)\n",
    "for model in structure:\n",
    "    for chain in model:\n",
    "        for residue in chain:\n",
    "            #print (str(chain.id),residue.id[1])\n",
    "            #print (str(chain.id),residue.id)\n",
    "            '''\n",
    "            if str(chain.id) == 'K':\n",
    "                print (residue.id[0])\n",
    "                '''\n",
    "            #print [residue.id[0]]\n",
    "            if allow_MSE:\n",
    "                if residue.id[0] == 'H_MSE':\n",
    "                    residues_resolved_per_chain[str(chain.id)].append(residue.id[1])\n",
    "                else:\n",
    "                    if not residue.id[0].startswith('H_'):\n",
    "                        residues_resolved_per_chain[str(chain.id)].append(residue.id[1])\n",
    "            else:\n",
    "                if not residue.id[0].startswith('H_'):\n",
    "                    residues_resolved_per_chain[str(chain.id)].append(residue.id[1])\n",
    "# Read in structure a                \n",
    "structure_b = PDBParser().get_structure('6AGB', '6AGB.pdb')\n",
    "residues_resolved_per_chain_b = defaultdict(list)\n",
    "for model_b in structure_b:\n",
    "    for chain_b in model_b:\n",
    "        for residue_b in chain_b:\n",
    "            #print (str(chain_b.id),residue_b.id[1])\n",
    "            #print (str(chain_b.id),residue_b.id)\n",
    "            '''\n",
    "            if str(chain_b.id) == 'K':\n",
    "                print (residue_b.id[0])\n",
    "                '''\n",
    "            #print [residue_b.id[0]]\n",
    "            if allow_MSE:\n",
    "                if residue_b.id[0] == 'H_MSE':\n",
    "                    residues_resolved_per_chain_b[str(chain_b.id)].append(residue_b.id[1])\n",
    "                else:\n",
    "                    if not residue_b.id[0].startswith('H_'):\n",
    "                        residues_resolved_per_chain_b[str(chain_b.id)].append(residue_b.id[1])\n",
    "            else:\n",
    "                if not residue_b.id[0].startswith('H_'):\n",
    "                    residues_resolved_per_chain_b[str(chain_b.id)].append(residue_b.id[1])\n",
    "\n",
    "# further prep for last section\n",
    "structures = (structure,structure_b) #will need for calling each in the order used later, i.e. structure a and b\n",
    "\n",
    "chain_pairs = [('A','F'),('B','G')] #putting chain identiifier from 'first' structure first in each pair.\n",
    "                \n",
    "#now that have position info for residues of both structures, get the shared positions\n",
    "shared_positions_per_chain_pairs = {}\n",
    "for chain_pair in chain_pairs:\n",
    "    shared = list(set(residues_resolved_per_chain[chain_pair[0]]) & set(residues_resolved_per_chain_b[chain_pair[1]]) )\n",
    "    shared_positions_per_chain_pairs[chain_pair] = shared\n",
    "\n",
    "#Now format more concisely\n",
    "print (\"Shared positions, concisely stated:\")\n",
    "ranges_o_residues_resolved_per_chain_pairs = {}\n",
    "for k,lst in shared_positions_per_chain_pairs.items():\n",
    "    print(k)\n",
    "    #print (list(range_extract(lst))) # to see the list of tuples unformatted\n",
    "    printr(range_extract(lst)) # tuples formatted as ranges\n",
    "    ranges_o_residues_resolved_per_chain_pairs[k] = get_nice_ranges_wcolon(range_extract(lst))\n",
    "# form commands\n",
    "formatted_commands = \"\"\n",
    "for chain_pair in ranges_o_residues_resolved_per_chain_pairs:\n",
    "    for indx,chain in enumerate(chain_pair):\n",
    "        formatted_commands += f\"select {structures[indx].id}ch{chain}CA,\" #`CA` at end stands for `name CA` / alpha-carbon\n",
    "        formatted_commands += \"|\".join( f\" {structures[indx].id} and resid {pos_range} and chain {chain} and name CA \" \n",
    "                                       for pos_range in ranges_o_residues_resolved_per_chain_pairs[chain_pair] ) \n",
    "        #for pos_range in ranges_o_residues_resolved_per_chain_pairs[chain_pair]:\n",
    "         #   formatted_commands += f\"{structures[indx].id} and resid {pos_range} and chain {chain} and name CA\"\n",
    "        formatted_commands += \"\\n\"\n",
    "\n",
    "# residues_resolved_per_chain_b\n",
    "shared_positions_per_chain_pairs\n",
    "ranges_o_residues_resolved_per_chain_pairs\n",
    "print(\"\\n\\n\")\n",
    "print (\"FORMATTED PYMOL COMMANDS:\")\n",
    "print(\" \")\n",
    "print(formatted_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = \"6c6l\"\n",
    "chain = \"A\"  #Vph1p chain in PDB id: 6c6l\n",
    "identical_color = \"[0.627,0.121,0.372]\"\n",
    "strong_siml_color = \"[0.937, 0.470, 0.627]\"\n",
    "weak_siml_color = \"[0.949, 0.784, 0.878]\"\n",
    "color_dict = {\n",
    "    \"identical\":identical_color,\n",
    "    \"strongly_similar\":strong_siml_color,\n",
    "    \"weakly_similar\":weak_siml_color\n",
    "            }\n",
    "df_dict = dict(zip(df.category,df.residue_positions))\n",
    "assert list(color_dict.keys()) == list(df_dict.keys())[:3] , \"keys not identical\"\n",
    "building_output = \"\"\n",
    "for category in df_dict:\n",
    "    if category != \"not_conserved\":\n",
    "        for res in df_dict[category]:\n",
    "            building_output += f\"select resi{res}, (chain {chain} and resi {res})\\n\"\n",
    "            building_output += f\"show spheres, resi{res}\\nset sphere_scale, 1, resi{res}\\n\"\n",
    "            building_output += f\"color {color_dict[category]}, resi{res}\\n\"\n",
    "        #save and reset output string\n",
    "        %store building_output > {category}_commands.txt\n",
    "        building_output = \"\"\n",
    "# Comment out the above line & uncomment the next line if you want to save as single file\n",
    "#%store building_output > all_commands.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head identical_commands.txt\n",
    "!echo \" \"\n",
    "!tail identical_commands.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrating outputting to a single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL to a single file\n",
    "structure = \"6c6l\"\n",
    "chain = \"A\"  #Vph1p chain in PDB id: 6c6l\n",
    "identical_color = \"[0.627,0.121,0.372]\"\n",
    "strong_siml_color = \"[0.937, 0.470, 0.627]\"\n",
    "weak_siml_color = \"[0.949, 0.784, 0.878]\"\n",
    "color_dict = {\n",
    "    \"identical\":identical_color,\n",
    "    \"strongly_similar\":strong_siml_color,\n",
    "    \"weakly_similar\":weak_siml_color\n",
    "            }\n",
    "df_dict = dict(zip(df.category,df.residue_positions))\n",
    "assert list(color_dict.keys()) == list(df_dict.keys())[:3] , \"keys not identical\"\n",
    "building_output = \"\"\n",
    "for category in df_dict:\n",
    "    if category != \"not_conserved\":\n",
    "        for res in df_dict[category]:\n",
    "            building_output += f\"select resi{res}, (chain {chain} and resi {res})\\n\"\n",
    "            building_output += f\"show spheres, resi{res}\\nset sphere_scale, 1, resi{res}\\n\"\n",
    "            building_output += f\"color {color_dict[category]}, resi{res}\\n\"\n",
    "%store building_output > all_commands.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing that worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head all_commands.txt\n",
    "!echo \" \"\n",
    "!tail all_commands.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the matching residue information to make Jmol commands\n",
    "\n",
    "A similar process can be done to make Jmol / JSmol command for the `compare` function, Jmol/JSmol's equivalent of Pymol's fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JMOL\n",
    "from categorize_residues_based_on_conservation_relative_consensus_line import categorize_residues_based_on_conservation_relative_consensus_line\n",
    "df = categorize_residues_based_on_conservation_relative_consensus_line(\"alignment.clw\",\"VPH1\", return_panel_data = True)\n",
    "structure = \"6c6l\"\n",
    "chain = \"A\"  #Vph1p chain in PDB id: 6c6l\n",
    "identical_color = \"[160,31,95]\"\n",
    "strong_siml_color = \"[239, 120, 160]\"\n",
    "weak_siml_color = \"[242, 200, 224]\"\n",
    "color_dict = {\n",
    "    \"identical\":identical_color,\n",
    "    \"strongly_similar\":strong_siml_color,\n",
    "    \"weakly_similar\":weak_siml_color\n",
    "            }\n",
    "df_dict = dict(zip(df.category,df.residue_positions))\n",
    "assert list(color_dict.keys()) == list(df_dict.keys())[:3] , \"keys not identical\"\n",
    "building_output = \"\"\n",
    "for category in df_dict:\n",
    "    if category != \"not_conserved\":\n",
    "        for res in df_dict[category]:\n",
    "            building_output += f\"select {res}:{chain};\"\n",
    "            building_output += f\"spacefill on;\"\n",
    "            building_output += f\"color {color_dict[category]}\\n\"\n",
    "        #save and reset output string\n",
    "        %store building_output > {category}_jmol_commands.txt\n",
    "        building_output = \"\"\n",
    "# Comment out the above line & uncomment the next line if you want to save as single file\n",
    "#%store building_output > all_jmol_commands.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jmol commands all in a single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from categorize_residues_based_on_conservation_relative_consensus_line import categorize_residues_based_on_conservation_relative_consensus_line\n",
    "df = categorize_residues_based_on_conservation_relative_consensus_line(\"alignment.clw\",\"VPH1\", return_panel_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JMOL\n",
    "structure = \"6c6l\"\n",
    "chain = \"A\"  #Vph1p chain in PDB id: 6c6l\n",
    "identical_color = \"[160,31,95]\"\n",
    "strong_siml_color = \"[239, 120, 160]\"\n",
    "weak_siml_color = \"[242, 200, 224]\"\n",
    "color_dict = {\n",
    "    \"identical\":identical_color,\n",
    "    \"strongly_similar\":strong_siml_color,\n",
    "    \"weakly_similar\":weak_siml_color\n",
    "            }\n",
    "df_dict = dict(zip(df.category,df.residue_positions))\n",
    "assert list(color_dict.keys()) == list(df_dict.keys())[:3] , \"keys not identical\"\n",
    "building_output = \"\"\n",
    "for category in df_dict:\n",
    "    if category != \"not_conserved\":\n",
    "        for res in df_dict[category]:\n",
    "            building_output += f\"select {res}:{chain};\"\n",
    "            building_output += f\"spacefill on;\"\n",
    "            building_output += f\"color {color_dict[category]}\\n\"\n",
    "%store building_output > all_jmol_commands.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing that worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head all_jmol_commands.txt\n",
    "!echo \" \"\n",
    "!tail all_jmol_commands.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
