{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and combine multi-model PDB files, a.k.a. NMR-style multiple model pdb files, using command line\n",
    "\n",
    "Expanded and live version of this nice page [here](https://strucbio.biologie.uni-konstanz.de/ccp4wiki/index.php/Split_NMR-style_multiple_model_pdb_files_into_individual_models) at the CCP4 user community wiki. (Only 'live' if you launched from the `launch binder` badge.)\n",
    "\n",
    "Note that certain molecular visualization tools have aspects that make models produced with some of these methods more suited than others. For example, as discussed [here](https://github.com/fomightez/structurework/tree/master/python_scripts#advanced-options), Jmol `model 0` has special meaning as select all models in Jmol. Only with my full-featured Python script, see below, do I address this limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "|Table of Contents|\n",
    "|:--|\n",
    "|[Preparation](#Preparation)|\n",
    "|[Bash split ](#Bash-method-to-split)|\n",
    "|[Awk split ](#Awk-method-to-split)|\n",
    "|[Bash/Awk split ](#Bash%2fAwk-method-to-split)|\n",
    "|[Perl split](#Perl-method-to-split)|\n",
    "|[Simple Python split](#Basic-Python-method-to-split)|\n",
    "|[Python script split](#Python-script-method-to-split)|\n",
    "|[Python script merge](#Python-script-method-to-merge)|\n",
    "|[Collect files](#Collect-files-for-easy-downloading)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Get files to use in demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  269k  100  269k    0     0   606k      0 --:--:-- --:--:-- --:--:--  606k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  694k  100  694k    0     0  1585k      0 --:--:-- --:--:-- --:--:-- 1581k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  382k  100  382k    0     0   974k      0 --:--:-- --:--:-- --:--:--  974k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  575k  100  575k    0     0  1486k      0 --:--:-- --:--:-- --:--:-- 1482k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  230k  100  230k    0     0   663k      0 --:--:-- --:--:-- --:--:--  663k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  900k  100  900k    0     0  2098k      0 --:--:-- --:--:-- --:--:-- 2093k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  429k  100  429k    0     0   738k      0 --:--:-- --:--:-- --:--:--  738k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  772k  100  772k    0     0  1795k      0 --:--:-- --:--:-- --:--:-- 1791k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  163k  100  163k    0     0   528k      0 --:--:-- --:--:-- --:--:--  528k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  445k  100  445k    0     0  1149k      0 --:--:-- --:--:-- --:--:-- 1146k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10699  100 10699    0     0  51936      0 --:--:-- --:--:-- --:--:-- 51936\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  124k  100  124k    0     0   397k      0 --:--:-- --:--:-- --:--:--  400k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 47719  100 47719    0     0   162k      0 --:--:-- --:--:-- --:--:--  162k\n"
     ]
    }
   ],
   "source": [
    "!curl -OL https://files.rcsb.org/download/1JOX.pdb.gz\n",
    "!gunzip 1JOX.pdb.gz\n",
    "!curl -OL https://files.rcsb.org/download/1G03.pdb.gz\n",
    "!gunzip 1G03.pdb.gz\n",
    "!curl -OL https://files.rcsb.org/download/1K8H.pdb.gz\n",
    "!gunzip 1K8H.pdb.gz\n",
    "!curl -OL https://files.rcsb.org/download/1g9e.pdb.gz\n",
    "!gunzip 1g9e.pdb.gz\n",
    "!curl -OL https://files.rcsb.org/download/1D3Z.pdb.gz\n",
    "!gunzip 1D3Z.pdb.gz\n",
    "!curl -OL https://files.rcsb.org/download/5ZUX.pdb.gz\n",
    "!gunzip 5ZUX.pdb.gz\n",
    "!mkdir pdbs\n",
    "!mv 5ZUX.pdb pdbs/\n",
    "!curl -OL https://files.rcsb.org/download/6BA3.pdb.gz\n",
    "!gunzip 6BA3.pdb.gz\n",
    "!mv 6BA3.pdb pdbs/\n",
    "!curl -OL https://files.rcsb.org/download/6GDK.pdb.gz\n",
    "!gunzip 6GDK.pdb.gz\n",
    "!mv 6GDK.pdb pdbs/\n",
    "!curl -OL https://files.rcsb.org/download/6H1K.pdb.gz\n",
    "!gunzip 6H1K.pdb.gz\n",
    "!mv 6H1K.pdb pdbs/\n",
    "!curl -OL https://files.rcsb.org/download/6EQY.pdb.gz\n",
    "!gunzip 6EQY.pdb.gz\n",
    "# Prepare a directory containing individual model files to use in merge example\n",
    "!mkdir models\n",
    "!curl -OL https://files.rcsb.org/download/1crn.pdb.gz\n",
    "!gunzip 1crn.pdb.gz\n",
    "!mv 1crn.pdb models/.\n",
    "!curl -OL https://files.rcsb.org/download/1tup.pdb.gz\n",
    "!gunzip 1tup.pdb.gz\n",
    "!mv 1tup.pdb models/.\n",
    "!curl -OL https://files.rcsb.org/download/1ehz.pdb.gz\n",
    "!gunzip 1ehz.pdb.gz\n",
    "!mv 1ehz.pdb models/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bash method to split\n",
    "\n",
    "Adapted to notebook from [here](https://strucbio.biologie.uni-konstanz.de/ccp4wiki/index.php/Split_NMR-style_multiple_model_pdb_files_into_individual_models):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    i=1\n",
    "    while read -a line; do\n",
    "        echo \"${line[@]}\" >> model_${i}.pdb\n",
    "        [[ ${line[0]} == ENDMDL ]] && ((i++))\n",
    "     done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 's' (str) to file 'split_into_models.sh'.\n",
      "\n",
      "\n",
      "i=1\n",
      "while read -a line; do\n",
      "    echo \"${line[@]}\" >> model_${i}.pdb\n",
      "    [[ ${line[0]} == ENDMDL ]] && ((i++))\n",
      " done\n"
     ]
    }
   ],
   "source": [
    "s='''i=1\n",
    "while read -a line; do\n",
    "    echo \"${line[@]}\" >> model_${i}.pdb\n",
    "    [[ ${line[0]} == ENDMDL ]] && ((i++))\n",
    " done'''\n",
    "\n",
    "%store s > split_into_models.sh\n",
    "\n",
    "#check file made\n",
    "print (\"\\n\")\n",
    "!head split_into_models.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run that:\n",
    "(You'd leave out the `!` if you were actually running this in a shell terminal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash split_into_models.sh < 1G03.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I originally used `!bash split_into_models.sh < 1G03.pdb`; however, got `read: Illegal option -a`. Switched to `bash` per [Biffen's comment here](https://stackoverflow.com/q/52364997/8508004).)\n",
    "\n",
    "That produces output files with names that start with `model_` before the model number . I'd prefer to tag them with the PDB id, too. Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for file in model_*.pdb ; do mv \"$file\" \"1G03${file}\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That could be done using purely Python with the following code:\n",
    "\n",
    "    tag_to_add =\"1G03\"\n",
    "    import os\n",
    "    import sys\n",
    "    import fnmatch\n",
    "    model_pattern = \"model_*.pdb\"\n",
    "    for file in os.listdir('.'):\n",
    "        if fnmatch.fnmatch(file, model_pattern):\n",
    "            os.rename(file, tag_to_add + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Awk method to split\n",
    "\n",
    "Adapted to notebook from [here](https://strucbio.biologie.uni-konstanz.de/ccp4wiki/index.php/Split_NMR-style_multiple_model_pdb_files_into_individual_models):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    BEGIN {file = 0; filename = \"model_\"  file \".pdb\"}\n",
    "    /ENDMDL/ {getline; file ++; filename = \"model_\" file \".pdb\"}\n",
    "    {print $0 > filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 's' (str) to file 'split_into_models.awk'.\n",
      "\n",
      "\n",
      "BEGIN {file = 0; filename = \"model_\"  file \".pdb\"}\n",
      "/ENDMDL/ {getline; file ++; filename = \"model_\" file \".pdb\"}\n",
      "{print $0 > filename}\n"
     ]
    }
   ],
   "source": [
    "s='''BEGIN {file = 0; filename = \"model_\"  file \".pdb\"}\n",
    "/ENDMDL/ {getline; file ++; filename = \"model_\" file \".pdb\"}\n",
    "{print $0 > filename}'''\n",
    "\n",
    "%store s > split_into_models.awk\n",
    "\n",
    "#check file made\n",
    "print (\"\\n\")\n",
    "!head  split_into_models.awk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run that:  \n",
    "(You'd leave out the `!` if you were actually running this in a shell terminal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk -f split_into_models.awk < 1JOX.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That produces output files with names that start with `model_` before the model number . I'd prefer to tag them with the PDB id, too. Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for file in model_*.pdb ; do mv \"$file\" \"1JOX${file}\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That could be done using purely Python with the following code:\n",
    "\n",
    "    tag_to_add =\"1JOX\"\n",
    "    import os\n",
    "    import sys\n",
    "    import fnmatch\n",
    "    model_pattern = \"model_*.pdb\"\n",
    "    for file in os.listdir('.'):\n",
    "        if fnmatch.fnmatch(file, model_pattern):\n",
    "            os.rename(file, tag_to_add + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bash/awk one-liner split\n",
    "\n",
    "Adapted to notebook from [here](https://strucbio.biologie.uni-konstanz.de/ccp4wiki/index.php/Split_NMR-style_multiple_model_pdb_files_into_individual_models):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    grep -n 'MODEL\\|ENDMDL' models.pdb | cut -d: -f 1 | \\\n",
    "    awk '{if(NR%2) printf \"sed -n %d,\",$1+1; else printf \"%dp models.pdb > model_%03d.pdb\\n\", $1-1,NR/2;}' |  bash -sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -n 'MODEL\\|ENDMDL' 1K8H.pdb | cut -d: -f 1 | awk '{if(NR%2) printf \"sed -n %d,\",$1+1; else printf \"%dp 1K8H.pdb > 1K8Hmodel_%03d.pdb\\n\", $1-1,NR/2;}' |  bash -sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike above, this time I edited the naming part of the command instead of changing from `model_####.pdb` after it had run and produced that style of output.\n",
    "\n",
    "(Note the first file it produced in this example doesn't look like it is an actual model file.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Perl method to split\n",
    "\n",
    "Adapted to notebook from [here](https://strucbio.biologie.uni-konstanz.de/ccp4wiki/index.php/Split_NMR-style_multiple_model_pdb_files_into_individual_models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%perl\n",
    "$base='1g9e';open(IN,\"<$base.pdb\");@indata = <IN>;$i=0;\n",
    "foreach $line(@indata) {\n",
    "if($line =~ /^MODEL/) {++$i;$file=\"${base}_$i.pdb\";open(OUT,\">$file\");next}\n",
    "if($line =~ /^ENDMDL/) {next}\n",
    "if($line =~ /^ATOM/ || $line =~ /^HETATM/) {print OUT \"$line\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Python method to split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This version here](https://github.com/fomightez/structurework/blob/master/python_scripts/super_basic_multiple_model_PDB_file_splitter.py) is fleshed out & documented a bit more from the code that I posted [this page](https://strucbio.biologie.uni-konstanz.de/ccp4wiki/index.php/Split_NMR-style_multiple_model_pdb_files_into_individual_models). Note that it starts the model number at one which works better with Jmol, see above.  \n",
    "The main part of the code is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     PDB_text = \"\"\"\n",
    "     PASTE YOUR PDB FILE TEXT HERE\n",
    "     \"\"\"\n",
    "\n",
    "     model_number = 1\n",
    "     new_file_text = \"\"\n",
    "     for line in filter(None, PDB_text.splitlines()):\n",
    "         line = line.strip () #for better control of ends of lines\n",
    "         if line == \"ENDMDL\":\n",
    "             # save file with file number in name\n",
    "             output_file = open(\"model_\" + str(model_number) + \".pdb\", \"w\")\n",
    "             output_file.write(new_file_text.rstrip('\\r\\n')) #rstrip to remove trailing newline\n",
    "             output_file.close()\n",
    "             # reset everything for next model\n",
    "             model_number += 1\n",
    "             new_file_text = \"\"\n",
    "         elif not line.startswith(\"MODEL\"):\n",
    "             new_file_text += line + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It requires you to hand-edit the code to actually paste in the **ENTIRE** PDB file. I suggest skipping to the 'Python script method to split' below as it is more convenient. I am only posting this to show the underlying the process.\n",
    "\n",
    "If you did prefer to use it, the following command would retrieve it into an active Jupyter session.\n",
    "\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/structurework/master/python_scripts/super_basic_multiple_model_PDB_file_splitter.py\n",
    "\n",
    "Following retrieval, you'd open the file and paste your PDB file of interest in place of the text `PASTE YOUR PDB FILE TEXT HERE`. And then run it. This command would be used on a generic command line. \n",
    "\n",
    "    python super_basic_multiple_model_PDB_file_splitter.py\n",
    "\n",
    "You can either enter that proceeded by an exclamation point in a notebook, or use this command in a cell in a notebook:\n",
    "\n",
    "    %run super_basic_multiple_model_PDB_file_splitter.py\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python script method to split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is more full featured and easier to use that the super basic python code version. However, the basic code above is a more concise representation of what goes on in the script.\n",
    "\n",
    "It can be pointed at a directory and process all the files ending in '.pdb' or '.PDB' in that folder.\n",
    "\n",
    "Note that it starts the model number at one which works better with Jmol, see above.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10343  100 10343    0     0  85479      0 --:--:-- --:--:-- --:--:-- 85479\n"
     ]
    }
   ],
   "source": [
    "# retrieve the script\n",
    "!curl -O https://raw.githubusercontent.com/fomightez/structurework/master/python_scripts/multiple_model_PDB_file_splitter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading in your file...\n",
      "Concluded. \n",
      "File split into 10 models. \n",
      "Files with names '1D3Z_model_1.pdb', '1D3Z_model_2.pdb', etc., \n",
      "have been created in same directory as the input file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the script\n",
    "%run multiple_model_PDB_file_splitter.py 1D3Z.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'd use the command below if you were working on an actual command line:\n",
    "\n",
    "    python multiple_model_PDB_file_splitter.py 1D3Z.pdb\n",
    "    \n",
    "Next is an example of having it act on a directory:\n",
    "\n",
    "First we'll check what the directory looks like before running the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ZUX.pdb  6BA3.pdb  6GDK.pdb  6H1K.pdb\n"
     ]
    }
   ],
   "source": [
    "!ls pdbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the script targeting that directory, you'd issue the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading in your file...\n",
      "Concluded. \n",
      "File split into 20 models. \n",
      "Files with names 'pdbs/5ZUX_model_1.pdb', 'pdbs/5ZUX_model_2.pdb', etc., \n",
      "have been created in same directory as the input file.\n",
      "\n",
      "Reading in your file...\n",
      "Concluded. \n",
      "File split into 20 models. \n",
      "Files with names 'pdbs/6GDK_model_1.pdb', 'pdbs/6GDK_model_2.pdb', etc., \n",
      "have been created in same directory as the input file.\n",
      "\n",
      "Reading in your file...\n",
      "Concluded. \n",
      "File split into 10 models. \n",
      "Files with names 'pdbs/6H1K_model_1.pdb', 'pdbs/6H1K_model_2.pdb', etc., \n",
      "have been created in same directory as the input file.\n",
      "\n",
      "Reading in your file...\n",
      "Concluded. \n",
      "File split into 20 models. \n",
      "Files with names 'pdbs/6BA3_model_1.pdb', 'pdbs/6BA3_model_2.pdb', etc., \n",
      "have been created in same directory as the input file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run multiple_model_PDB_file_splitter.py pdbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ZUX_model_10.pdb  5ZUX_model_9.pdb   6BA3_model_7.pdb\t 6GDK_model_5.pdb\n",
      "5ZUX_model_11.pdb  5ZUX.pdb\t      6BA3_model_8.pdb\t 6GDK_model_6.pdb\n",
      "5ZUX_model_12.pdb  6BA3_model_10.pdb  6BA3_model_9.pdb\t 6GDK_model_7.pdb\n",
      "5ZUX_model_13.pdb  6BA3_model_11.pdb  6BA3.pdb\t\t 6GDK_model_8.pdb\n",
      "5ZUX_model_14.pdb  6BA3_model_12.pdb  6GDK_model_10.pdb  6GDK_model_9.pdb\n",
      "5ZUX_model_15.pdb  6BA3_model_13.pdb  6GDK_model_11.pdb  6GDK.pdb\n",
      "5ZUX_model_16.pdb  6BA3_model_14.pdb  6GDK_model_12.pdb  6H1K_model_10.pdb\n",
      "5ZUX_model_17.pdb  6BA3_model_15.pdb  6GDK_model_13.pdb  6H1K_model_1.pdb\n",
      "5ZUX_model_18.pdb  6BA3_model_16.pdb  6GDK_model_14.pdb  6H1K_model_2.pdb\n",
      "5ZUX_model_19.pdb  6BA3_model_17.pdb  6GDK_model_15.pdb  6H1K_model_3.pdb\n",
      "5ZUX_model_1.pdb   6BA3_model_18.pdb  6GDK_model_16.pdb  6H1K_model_4.pdb\n",
      "5ZUX_model_20.pdb  6BA3_model_19.pdb  6GDK_model_17.pdb  6H1K_model_5.pdb\n",
      "5ZUX_model_2.pdb   6BA3_model_1.pdb   6GDK_model_18.pdb  6H1K_model_6.pdb\n",
      "5ZUX_model_3.pdb   6BA3_model_20.pdb  6GDK_model_19.pdb  6H1K_model_7.pdb\n",
      "5ZUX_model_4.pdb   6BA3_model_2.pdb   6GDK_model_1.pdb\t 6H1K_model_8.pdb\n",
      "5ZUX_model_5.pdb   6BA3_model_3.pdb   6GDK_model_20.pdb  6H1K_model_9.pdb\n",
      "5ZUX_model_6.pdb   6BA3_model_4.pdb   6GDK_model_2.pdb\t 6H1K.pdb\n",
      "5ZUX_model_7.pdb   6BA3_model_5.pdb   6GDK_model_3.pdb\n",
      "5ZUX_model_8.pdb   6BA3_model_6.pdb   6GDK_model_4.pdb\n"
     ]
    }
   ],
   "source": [
    "!ls pdbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next final section of this notebook will use these files as an example of how to easily package them up for downloading to your local machines. See [Collect files for easy downloading](#Collect-files-for-easy-downloading)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Python script method to merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script takes a directory as input and makes a single multi-model PDB file of any files ending in '.pdb' or '.PDB' in that folder.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12390  100 12390    0     0  87253      0 --:--:-- --:--:-- --:--:-- 87253\n"
     ]
    }
   ],
   "source": [
    "# retrieve the script\n",
    "!curl -O https://raw.githubusercontent.com/fomightez/structurework/master/python_scripts/merge_multi_PDBs_into_single_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6146.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6147.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 6148.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 6149.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain F is discontinuous at line 6171.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6185.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6383.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 6453.\n",
      "  PDBConstructionWarning)\n",
      "\n",
      "Processing <Structure id=models/1ehz>; it will be model #1\n",
      "Processing <Structure id=models/1crn>; it will be model #2\n",
      "Processing <Structure id=models/1tup>; it will be model #3\n",
      "\n",
      "The PDB-formatted file models.pdb has been created.\n"
     ]
    }
   ],
   "source": [
    "%run merge_multi_PDBs_into_single_file.py models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will further show that running that last cell resulted in creating a file with multiple models from three individual structure files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL      1\n",
      "ATOM      1  OP3   G A   1      50.193  51.190  50.534  1.00 99.85           O  \n",
      "ATOM      2  P     G A   1      50.626  49.730  50.573  1.00100.19           P  \n",
      "ATOM      3  OP1   G A   1      49.854  48.893  49.562  1.00100.19           O  \n",
      "ATOM      4  OP2   G A   1      52.137  49.542  50.511  1.00 99.21           O  \n",
      "ATOM      5  O5'   G A   1      50.161  49.136  52.023  1.00 99.82           O  \n",
      "ATOM      6  C5'   G A   1      50.216  49.948  53.210  1.00 98.63           C  \n",
      "ATOM      7  C4'   G A   1      50.968  49.231  54.309  1.00 97.84           C  \n",
      "ATOM      8  O4'   G A   1      50.450  47.888  54.472  1.00 97.10           O  \n",
      "ATOM      9  C3'   G A   1      52.454  49.030  54.074  1.00 98.07           C  \n"
     ]
    }
   ],
   "source": [
    "!head models.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script has two optional features that can be used:\n",
    "\n",
    "- The starting model number is customizable.\n",
    "- By adjusting the file names, an order can be specified for the models in the resulting file.\n",
    "\n",
    "These are each are demonstrated next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demonstrating customizing the starting number of models**\n",
    "\n",
    "You can specify a first model number using the `--initial` option, abbreviated `-i`, followed by the integer value to start with and then all subsequent models will be next in line following that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6146.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6147.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 6148.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 6149.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain F is discontinuous at line 6171.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6185.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6383.\n",
      "  PDBConstructionWarning)\n",
      "/srv/conda/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:90: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 6453.\n",
      "  PDBConstructionWarning)\n",
      "\n",
      "Processing <Structure id=models/1ehz>; it will be model #23\n",
      "Processing <Structure id=models/1crn>; it will be model #24\n",
      "Processing <Structure id=models/1tup>; it will be model #25\n",
      "\n",
      "The PDB-formatted file models.pdb has been created.\n"
     ]
    }
   ],
   "source": [
    "%run merge_multi_PDBs_into_single_file.py models -i 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line will show that the option worked to number the starting model as 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL      23\n",
      "ATOM      1  OP3   G A   1      50.193  51.190  50.534  1.00 99.85           O  \n",
      "ATOM      2  P     G A   1      50.626  49.730  50.573  1.00100.19           P  \n",
      "ATOM      3  OP1   G A   1      49.854  48.893  49.562  1.00100.19           O  \n",
      "ATOM      4  OP2   G A   1      52.137  49.542  50.511  1.00 99.21           O  \n",
      "ATOM      5  O5'   G A   1      50.161  49.136  52.023  1.00 99.82           O  \n",
      "ATOM      6  C5'   G A   1      50.216  49.948  53.210  1.00 98.63           C  \n",
      "ATOM      7  C4'   G A   1      50.968  49.231  54.309  1.00 97.84           C  \n",
      "ATOM      8  O4'   G A   1      50.450  47.888  54.472  1.00 97.10           O  \n",
      "ATOM      9  C3'   G A   1      52.454  49.030  54.074  1.00 98.07           C  \n"
     ]
    }
   ],
   "source": [
    "!head models.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero cannot be used in the script. You'd have to adjust them after if you needed that value in the file name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demonstrating ordering the models**\n",
    "\n",
    "If you add numbers to the file names you can specify the order of the files in the model. For example, above `1ehz.pdb` was used as the first model by default. If that had been intended to be the third model, you could change the file names of the pdb files to be like this:\n",
    "\n",
    "- `1crn_3.pdb`\n",
    "- `1tup_5.pdb`\n",
    "- `1ehz_7.pdb`\n",
    "\n",
    "\n",
    "The specific numbers don't matter. The lowest are first and the highest numbered will be last.\n",
    "\n",
    "I'll leave that exercise to the user and instead demonstrate the script further with a larger group of files.  \n",
    "A merge based on that pattern of files names will be demonstrated by running the next two cells. First, we'll prepare a new version of the models directory using the split methods from above to make files with names matching that pattern and then run the merge script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_10.pdb  model_14.pdb  model_18.pdb  model_2.pdb  model_6.pdb\n",
      "model_11.pdb  model_15.pdb  model_19.pdb  model_3.pdb  model_7.pdb\n",
      "model_12.pdb  model_16.pdb  model_20.pdb  model_4.pdb  model_8.pdb\n",
      "model_13.pdb  model_17.pdb  model_21.pdb  model_5.pdb  model_9.pdb\n"
     ]
    }
   ],
   "source": [
    "# Prepare a directory containing individual model files to use.\n",
    "# First clear current `models` content.\n",
    "!rm -rf models\n",
    "# now prepare the directory with a new listing of files\n",
    "!grep -n 'MODEL\\|ENDMDL' 1G03.pdb | cut -d: -f 1 | awk '{if(NR%2) printf \"sed -n %d,\",$1+1; else printf \"%dp 1G03.pdb > model_%01d.pdb\\n\", $1-1,NR/2;}' |  bash -sf\n",
    "!rm  model_1.pdb # like in earlier demo above, first resulting supposed 'model' is just part of header and so delete\n",
    "!mkdir models\n",
    "!mv model_*.pdb models/\n",
    "!ls models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that because the first generated 'model', `model_1.pdb`, was just made of part of the header it was deleted as part of the preparation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <Structure id=models/model_2>; it will be model #1\n",
      "Processing <Structure id=models/model_3>; it will be model #2\n",
      "Processing <Structure id=models/model_4>; it will be model #3\n",
      "Processing <Structure id=models/model_5>; it will be model #4\n",
      "Processing <Structure id=models/model_6>; it will be model #5\n",
      "Processing <Structure id=models/model_7>; it will be model #6\n",
      "Processing <Structure id=models/model_8>; it will be model #7\n",
      "Processing <Structure id=models/model_9>; it will be model #8\n",
      "Processing <Structure id=models/model_10>; it will be model #9\n",
      "Processing <Structure id=models/model_11>; it will be model #10\n",
      "Processing <Structure id=models/model_12>; it will be model #11\n",
      "Processing <Structure id=models/model_13>; it will be model #12\n",
      "Processing <Structure id=models/model_14>; it will be model #13\n",
      "Processing <Structure id=models/model_15>; it will be model #14\n",
      "Processing <Structure id=models/model_16>; it will be model #15\n",
      "Processing <Structure id=models/model_17>; it will be model #16\n",
      "Processing <Structure id=models/model_18>; it will be model #17\n",
      "Processing <Structure id=models/model_19>; it will be model #18\n",
      "Processing <Structure id=models/model_20>; it will be model #19\n",
      "Processing <Structure id=models/model_21>; it will be model #20\n",
      "\n",
      "The PDB-formatted file models.pdb has been created.\n"
     ]
    }
   ],
   "source": [
    "%run merge_multi_PDBs_into_single_file.py models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL      1\n",
      "ATOM      1  N   PRO A   1       4.524   9.887  -0.667  1.00  0.00           N  \n",
      "ATOM      2  CA  PRO A   1       5.918  10.123  -0.175  1.00  0.00           C  \n",
      "ATOM      3  C   PRO A   1       5.865  10.943   1.122  1.00  0.00           C  \n",
      "ATOM      4  O   PRO A   1       5.284  12.009   1.177  1.00  0.00           O  \n",
      "ATOM      5  CB  PRO A   1       6.697  10.871  -1.278  1.00  0.00           C  \n",
      "ATOM      6  CG  PRO A   1       5.715  11.124  -2.430  1.00  0.00           C  \n",
      "ATOM      7  CD  PRO A   1       4.374  10.484  -2.030  1.00  0.00           C  \n",
      "ATOM      8  H   PRO A   1       4.341   8.864  -0.711  1.00  0.00           H  \n",
      "ATOM      9  H3  PRO A   1       3.846  10.334  -0.018  1.00  0.00           H  \n"
     ]
    }
   ],
   "source": [
    "!head models.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest numbered model was used first and then the numbers increased to match from there.\n",
    "\n",
    "Note that all need to match the pattern of having an integer after an underscore and before the `.pdb` or `.PDB`. If a single one doesn't match, the order will just be based on the order the files happened to get processed in. For example, if we change one of the file names to not have a number, we can see the processing won't be as ordered in the series like it was in the last run of the script above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <Structure id=models/model_11>; it will be model #1\n",
      "Processing <Structure id=models/model_15>; it will be model #2\n",
      "Processing <Structure id=models/model_5>; it will be model #3\n",
      "Processing <Structure id=models/model_12>; it will be model #4\n",
      "Processing <Structure id=models/model_7>; it will be model #5\n",
      "Processing <Structure id=models/model_a>; it will be model #6\n",
      "Processing <Structure id=models/model_13>; it will be model #7\n",
      "Processing <Structure id=models/model_4>; it will be model #8\n",
      "Processing <Structure id=models/model_10>; it will be model #9\n",
      "Processing <Structure id=models/model_17>; it will be model #10\n",
      "Processing <Structure id=models/model_3>; it will be model #11\n",
      "Processing <Structure id=models/model_19>; it will be model #12\n",
      "Processing <Structure id=models/model_9>; it will be model #13\n",
      "Processing <Structure id=models/model_20>; it will be model #14\n",
      "Processing <Structure id=models/model_21>; it will be model #15\n",
      "Processing <Structure id=models/model_16>; it will be model #16\n",
      "Processing <Structure id=models/model_6>; it will be model #17\n",
      "Processing <Structure id=models/model_8>; it will be model #18\n",
      "Processing <Structure id=models/model_18>; it will be model #19\n",
      "Processing <Structure id=models/model_14>; it will be model #20\n",
      "\n",
      "The PDB-formatted file models.pdb has been created.\n"
     ]
    }
   ],
   "source": [
    "#break it by changing lowest numbered one to have a letter instead of a number.\n",
    "!mv models/model_2.pdb models/model_a.pdb \n",
    "%run merge_multi_PDBs_into_single_file.py models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the order of the files merged into the model file was much more haphazard.\n",
    "\n",
    "Let's fix it and further demonstrate it isn't the specific number that matters, but the order.\n",
    "!mv models/model_a.pdb models/model_0.pdb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <Structure id=models/model_0>; it will be model #1\n",
      "Processing <Structure id=models/model_3>; it will be model #2\n",
      "Processing <Structure id=models/model_4>; it will be model #3\n",
      "Processing <Structure id=models/model_5>; it will be model #4\n",
      "Processing <Structure id=models/model_6>; it will be model #5\n",
      "Processing <Structure id=models/model_7>; it will be model #6\n",
      "Processing <Structure id=models/model_8>; it will be model #7\n",
      "Processing <Structure id=models/model_9>; it will be model #8\n",
      "Processing <Structure id=models/model_10>; it will be model #9\n",
      "Processing <Structure id=models/model_11>; it will be model #10\n",
      "Processing <Structure id=models/model_12>; it will be model #11\n",
      "Processing <Structure id=models/model_13>; it will be model #12\n",
      "Processing <Structure id=models/model_14>; it will be model #13\n",
      "Processing <Structure id=models/model_15>; it will be model #14\n",
      "Processing <Structure id=models/model_16>; it will be model #15\n",
      "Processing <Structure id=models/model_17>; it will be model #16\n",
      "Processing <Structure id=models/model_18>; it will be model #17\n",
      "Processing <Structure id=models/model_19>; it will be model #18\n",
      "Processing <Structure id=models/model_20>; it will be model #19\n",
      "Processing <Structure id=models/model_21>; it will be model #20\n",
      "\n",
      "The PDB-formatted file models.pdb has been created.\n"
     ]
    }
   ],
   "source": [
    "# Here will set the one file number lower than what it was originally.\n",
    "!mv models/model_a.pdb models/model_0.pdb\n",
    "%run merge_multi_PDBs_into_single_file.py models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, negative values can even work. (Although best avoided in general to make parsing file names more robust.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <Structure id=models/model_-1>; it will be model #1\n",
      "Processing <Structure id=models/model_3>; it will be model #2\n",
      "Processing <Structure id=models/model_4>; it will be model #3\n",
      "Processing <Structure id=models/model_5>; it will be model #4\n",
      "Processing <Structure id=models/model_6>; it will be model #5\n",
      "Processing <Structure id=models/model_7>; it will be model #6\n",
      "Processing <Structure id=models/model_8>; it will be model #7\n",
      "Processing <Structure id=models/model_9>; it will be model #8\n",
      "Processing <Structure id=models/model_10>; it will be model #9\n",
      "Processing <Structure id=models/model_11>; it will be model #10\n",
      "Processing <Structure id=models/model_12>; it will be model #11\n",
      "Processing <Structure id=models/model_13>; it will be model #12\n",
      "Processing <Structure id=models/model_14>; it will be model #13\n",
      "Processing <Structure id=models/model_15>; it will be model #14\n",
      "Processing <Structure id=models/model_16>; it will be model #15\n",
      "Processing <Structure id=models/model_17>; it will be model #16\n",
      "Processing <Structure id=models/model_18>; it will be model #17\n",
      "Processing <Structure id=models/model_19>; it will be model #18\n",
      "Processing <Structure id=models/model_20>; it will be model #19\n",
      "Processing <Structure id=models/model_21>; it will be model #20\n",
      "\n",
      "The PDB-formatted file models.pdb has been created.\n"
     ]
    }
   ],
   "source": [
    "!mv models/model_0.pdb models/model_-1.pdb\n",
    "%run merge_multi_PDBs_into_single_file.py models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect files for easy downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this example easier, we'll first change directories into the directory where we last split multi-model files into individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/pdbs\n",
      "5ZUX_model_10.pdb  5ZUX_model_9.pdb   6BA3_model_7.pdb\t 6GDK_model_5.pdb\n",
      "5ZUX_model_11.pdb  5ZUX.pdb\t      6BA3_model_8.pdb\t 6GDK_model_6.pdb\n",
      "5ZUX_model_12.pdb  6BA3_model_10.pdb  6BA3_model_9.pdb\t 6GDK_model_7.pdb\n",
      "5ZUX_model_13.pdb  6BA3_model_11.pdb  6BA3.pdb\t\t 6GDK_model_8.pdb\n",
      "5ZUX_model_14.pdb  6BA3_model_12.pdb  6GDK_model_10.pdb  6GDK_model_9.pdb\n",
      "5ZUX_model_15.pdb  6BA3_model_13.pdb  6GDK_model_11.pdb  6GDK.pdb\n",
      "5ZUX_model_16.pdb  6BA3_model_14.pdb  6GDK_model_12.pdb  6H1K_model_10.pdb\n",
      "5ZUX_model_17.pdb  6BA3_model_15.pdb  6GDK_model_13.pdb  6H1K_model_1.pdb\n",
      "5ZUX_model_18.pdb  6BA3_model_16.pdb  6GDK_model_14.pdb  6H1K_model_2.pdb\n",
      "5ZUX_model_19.pdb  6BA3_model_17.pdb  6GDK_model_15.pdb  6H1K_model_3.pdb\n",
      "5ZUX_model_1.pdb   6BA3_model_18.pdb  6GDK_model_16.pdb  6H1K_model_4.pdb\n",
      "5ZUX_model_20.pdb  6BA3_model_19.pdb  6GDK_model_17.pdb  6H1K_model_5.pdb\n",
      "5ZUX_model_2.pdb   6BA3_model_1.pdb   6GDK_model_18.pdb  6H1K_model_6.pdb\n",
      "5ZUX_model_3.pdb   6BA3_model_20.pdb  6GDK_model_19.pdb  6H1K_model_7.pdb\n",
      "5ZUX_model_4.pdb   6BA3_model_2.pdb   6GDK_model_1.pdb\t 6H1K_model_8.pdb\n",
      "5ZUX_model_5.pdb   6BA3_model_3.pdb   6GDK_model_20.pdb  6H1K_model_9.pdb\n",
      "5ZUX_model_6.pdb   6BA3_model_4.pdb   6GDK_model_2.pdb\t 6H1K.pdb\n",
      "5ZUX_model_7.pdb   6BA3_model_5.pdb   6GDK_model_3.pdb\n",
      "5ZUX_model_8.pdb   6BA3_model_6.pdb   6GDK_model_4.pdb\n"
     ]
    }
   ],
   "source": [
    "%cd pdbs\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can package up the individual models into one easy to download archive with commands like these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czf 5ZUX_chains.tar.gz 5ZUX_model_*.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czf 6BA3_chains.tar.gz 6BA3_model_*.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czf 6GDK_chains.tar.gz 6GDK_model_*.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czf 6H1K_chains.tar.gz 6H1K_model_*.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify it worked by viewing the list of the files in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ZUX_chains.tar.gz  5ZUX_model_9.pdb\t6BA3_model_7.pdb    6GDK_model_5.pdb\n",
      "5ZUX_model_10.pdb   5ZUX.pdb\t\t6BA3_model_8.pdb    6GDK_model_6.pdb\n",
      "5ZUX_model_11.pdb   6BA3_chains.tar.gz\t6BA3_model_9.pdb    6GDK_model_7.pdb\n",
      "5ZUX_model_12.pdb   6BA3_model_10.pdb\t6BA3.pdb\t    6GDK_model_8.pdb\n",
      "5ZUX_model_13.pdb   6BA3_model_11.pdb\t6GDK_chains.tar.gz  6GDK_model_9.pdb\n",
      "5ZUX_model_14.pdb   6BA3_model_12.pdb\t6GDK_model_10.pdb   6GDK.pdb\n",
      "5ZUX_model_15.pdb   6BA3_model_13.pdb\t6GDK_model_11.pdb   6H1K_chains.tar.gz\n",
      "5ZUX_model_16.pdb   6BA3_model_14.pdb\t6GDK_model_12.pdb   6H1K_model_10.pdb\n",
      "5ZUX_model_17.pdb   6BA3_model_15.pdb\t6GDK_model_13.pdb   6H1K_model_1.pdb\n",
      "5ZUX_model_18.pdb   6BA3_model_16.pdb\t6GDK_model_14.pdb   6H1K_model_2.pdb\n",
      "5ZUX_model_19.pdb   6BA3_model_17.pdb\t6GDK_model_15.pdb   6H1K_model_3.pdb\n",
      "5ZUX_model_1.pdb    6BA3_model_18.pdb\t6GDK_model_16.pdb   6H1K_model_4.pdb\n",
      "5ZUX_model_20.pdb   6BA3_model_19.pdb\t6GDK_model_17.pdb   6H1K_model_5.pdb\n",
      "5ZUX_model_2.pdb    6BA3_model_1.pdb\t6GDK_model_18.pdb   6H1K_model_6.pdb\n",
      "5ZUX_model_3.pdb    6BA3_model_20.pdb\t6GDK_model_19.pdb   6H1K_model_7.pdb\n",
      "5ZUX_model_4.pdb    6BA3_model_2.pdb\t6GDK_model_1.pdb    6H1K_model_8.pdb\n",
      "5ZUX_model_5.pdb    6BA3_model_3.pdb\t6GDK_model_20.pdb   6H1K_model_9.pdb\n",
      "5ZUX_model_6.pdb    6BA3_model_4.pdb\t6GDK_model_2.pdb    6H1K.pdb\n",
      "5ZUX_model_7.pdb    6BA3_model_5.pdb\t6GDK_model_3.pdb\n",
      "5ZUX_model_8.pdb    6BA3_model_6.pdb\t6GDK_model_4.pdb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of the files produced from the commands just above:\n",
    "\n",
    "* `5ZUX_chains.tar.gz`\n",
    "* `6BA3_chains.tar.gz`\n",
    "* `6GDK_chains.tar.gz`\n",
    "* `6H1K_chains.tar.gz`\n",
    "\n",
    "**Download the gzipped tarballed archives produced to your local machine.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
